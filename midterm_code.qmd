
---
title: "Your Title Goes Here"
subtitle: "A report to the Quantum Insight AI research team."
author: "My Name"
date: last-modified
format:
  pdf:
    number-sections: true
    indent: true
    toc: false
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
execute:
  echo: false
---

# Statement of the Problem



# Summary of Findings



# Recommendations



# Appendix

```{r, include=FALSE}
library(quanteda)
library(quanteda.textstats)
library(tidyverse)
library(knitr)
library(gt)
library(syuzhet)
library(dplyr)
library(nFactors)
source("../R/helper_functions.R")
source("../R/keyness_functions.R")
source("../R/mda_functions.R")

```

```{r}
### Generate arxiv sub DFM from SPACY ####

arxiv_spacy <- read.table("arxiv_sample/arxiv_spacy.tsv", header=TRUE, sep='\t', quote="", fill=TRUE)

anno_edit_arxiv <- structure(arxiv_spacy, class = c("spacyr_parsed", "data.frame"))

subtkns_arxiv <- as.tokens(anno_edit_arxiv, include_pos = "tag", concatenator = "")
doc_categories_arxiv <- names(subtkns_arxiv) %>%
  data.frame(text_type = .) %>%
  mutate(text_type = str_extract(text_type, "^[a-z]+"))

docvars(subtkns_arxiv) <- doc_categories_arxiv

sub_dfm_arxiv <- subtkns_arxiv %>%
  tokens_select("^.[a-zA-Z0-9]+.[a-z]", selection = "keep", valuetype = "regex", case_insensitive = T) %>%
  dfm()

textstat_frequency(sub_dfm_arxiv, n = 10) |>
  gt() |>
  as_raw_html()

```

```{r}
### Generate ML3s sub DFM from SPACY ####

meta_llama_3_spacy <- read.table("hape_sample/spacy_data/spacy_Meta-Llama-3-8B.tsv", header=TRUE, sep='\t', quote="", fill=TRUE)

anno_edit_ml3s <- structure(meta_llama_3_spacy, class = c("spacyr_parsed", "data.frame"))

subtkns_ml3s <- as.tokens(anno_edit_ml3s, include_pos = "tag", concatenator = "")
doc_categories_ml3s <- names(subtkns_ml3s) %>%
  data.frame(text_type = .) %>%
  mutate(text_type = str_extract(text_type, "^[a-z]+"))

docvars(subtkns_ml3s) <- doc_categories_ml3s

sub_dfm_ml3s <- subtkns_ml3s %>%
  tokens_select("^.[a-zA-Z0-9]+.[a-z]", selection = "keep", valuetype = "regex", case_insensitive = T) %>%
  dfm()

textstat_frequency(sub_dfm_ml3s, n = 10) |>
  gt() |>
  as_raw_html()

```

```{r}
### Generate chatGPT4.0 sub DFM from SPACY ####

gpt_4o_spacy <- read.table("hape_sample/spacy_data/spacy_gpt-4o-2024-08-06.tsv", header=TRUE, sep='\t', quote="", fill=TRUE)

anno_edit_gpt4o <- structure(gpt_4o_spacy, class = c("spacyr_parsed", "data.frame"))

subtkns_gpt4o <- as.tokens(anno_edit_gpt4o, include_pos = "tag", concatenator = "")

doc_categories_gpt4o <- names(subtkns_gpt4o) %>%
  data.frame(text_type = .) %>%
  mutate(text_type = str_extract(text_type, "^[a-z]+"))

docvars(subtkns_gpt4o) <- doc_categories_gpt4o

sub_dfm_gpt4o <- subtkns_gpt4o %>%
  tokens_select("^.[a-zA-Z0-9]+.[a-z]", selection = "keep", valuetype = "regex", case_insensitive = T) %>%
  dfm()

textstat_frequency(sub_dfm_gpt4o, n = 10) |>
  gt() |>
  as_raw_html()

```

```{r}
### Generate chunk sub DFM from SPACY ####

chunk_spacy <- read.table("hape_sample/spacy_data/spacy_chunk_2.tsv", header=TRUE, sep='\t', quote="", fill=TRUE)

anno_edit_chunk <- structure(chunk_spacy, class = c("spacyr_parsed", "data.frame"))

subtkns_chunk <- as.tokens(anno_edit_chunk, include_pos = "tag", concatenator = "")
doc_categories_chunk <- names(subtkns_chunk) %>%
  data.frame(text_type = .) %>%
  mutate(text_type = str_extract(text_type, "^[a-z]+"))

docvars(subtkns_chunk) <- doc_categories_chunk

sub_dfm_chunk <- subtkns_chunk %>%
  tokens_select("^.[a-zA-Z0-9]+.[a-z]", selection = "keep", valuetype = "regex", case_insensitive = T) %>%
  dfm()

textstat_frequency(sub_dfm_chunk, n = 10) |>
  gt() |>
  as_raw_html()

```


```{r}
### KEYNESS TABLES ####
###Key: jj = adj.; vb = verb; nn = noun, prp = pronoun; vbp = ??? rb = ???, in/to = preposition
harris_v_obama <- keyness_table(harris_all_dfm, obama_all_dfm) %>%
  separate(col = Token, into = c("Token", "Tag"), sep = "_") %>%
  filter(Tag == "jj") %>%
  select(-Tag) %>%
  select(-DP_Ref)

harris_v_obama |>
  head(10) |>
  gt() |>
  tab_header(
    title = "Keyness Table",
    subtitle = "Comparison of Harris to the Obama reference corpus"
  ) |>
  fmt_number(columns = c('LL', 'LR', 'Per_10.3_Tar', 'Per_10.3_Ref'), decimals = 2) |>
  fmt_number(columns = c('DP_Tar'), decimals = 3) |>
  fmt_number(columns = c('PV'), decimals = 5) |>
  tab_options(data_row.padding = px(2), 
              column_labels.padding = px(2), 
              heading.padding = px(2),
              heading.title.font.size = "small",
              heading.subtitle.font.size = "small",
              table.font.size = "small",
              table.align = "left")
```


```{r, include = FALSE}
####read in biber data ####
human_chunk_biber <- read_tsv("hape_sample/biber_data/biber_chunk_2.tsv")

gpt_4o_biber <- read_tsv("hape_sample/biber_data/biber_gpt-4o-2024-08-06.tsv")

meta_llama_3_biber <- read_tsv("hape_sample/biber_data/biber_Meta-Llama-3-8B.tsv")

arxiv_biber <- read_tsv("arxiv_sample/arxiv_biber.tsv")

text_chunk <- read_tsv("hape_sample/text_data/text_chunk_2.tsv")

```

```{r}

arxiv_biber_human <- arxiv_biber %>% 
  filter(str_detect(doc_id, "human")) %>%
  select(where(~ is.numeric(.x) && sum(.x) != 0))

arxiv_biber_machine <- arxiv_biber %>% 
  filter(str_detect(doc_id, "machine")) %>%
  select(where(~ is.numeric(.x) && sum(.x) != 0))

# only filter arxiv out 

```

```{r}
bc_cor <- cor(arxiv_biber_human[-1], method = "pearson")
corrplot::corrplot(bc_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, diag = F, tl.cex = 0.5)
```
```{r}
bc_cor <- cor(arxiv_biber_machine[-1], method = "pearson")
corrplot::corrplot(bc_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, diag = F, tl.cex = 0.5)
```

```{r}
bc_cor <- cor(human_chunk_biber[-1], method = "pearson")
corrplot::corrplot(bc_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, diag = F, tl.cex = 0.5)
```
```{r}
bc_cor <- cor(gpt_4o_biber[-1], method = "pearson")
corrplot::corrplot(bc_cor, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45, diag = F, tl.cex = 0.5)
```


```{r}
screeplot_mda(chunk_biber)
```

```{r}
heatmap_mda(bc_mda, n_factor = 1)
```
